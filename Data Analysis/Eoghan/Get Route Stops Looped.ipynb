{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do we not need to extract route stops based on journey pattern ID and not just  LineID alone???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Static Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lines = ['1', '102', '104', '11', '111', '114', '116', '118', '120', '122', '123', '13', '130', '14', '140', '142', '145', '14C', '15', '150', '151', '15A', '15B', '16', '161', '16C', '17', '17A', '18', '184', '185', '220', '236', '238', '239', '25', '25A', '25B', '25X', '26', '27', '270', '27A', '27B', '27X', '29A', '31', '31A', '31B', '32', '32X', '33', '332', '33A', '33B', '33X', '37', '38', '38A', '38B', '39', '39A', '4', '40', '40B', '40D', '41', '41A', '41B', '41C', '41X', '42', '43', '44', '44B', '45A', '46A', '46E', '47', '49', '51D', '51X', '53', '54A', '56A', '59', '61', '63', '65', '65B', '66', '66A', '66B', '66X', '67', '67X', '68', '68A', '69', '69X', '7', '70', '747', '75', '76', '76A', '77A', '79', '79A', '7B', '7D', '8', '83', '83A', '84', '84A', '84X', '86', '9']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119\n"
     ]
    }
   ],
   "source": [
    "print(len(lines))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Looped Writing of Route Stops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "1002\n",
      "1001\n",
      "1\n",
      "3\n",
      "1\n",
      "1002\n",
      "1001\n",
      "1\n",
      "1001\n",
      "1001\n",
      "1\n",
      "1002\n",
      "2\n",
      "1001\n",
      "1\n",
      "1\n",
      "1001\n",
      "1002\n",
      "1001\n",
      "1\n",
      "1001\n",
      "1\n",
      "1001\n",
      "1002\n",
      "2\n",
      "1\n",
      "1001\n",
      "1002\n",
      "2\n",
      "1001\n",
      "1\n",
      "2\n",
      "1002\n",
      "7\n",
      "2\n",
      "4\n",
      "1001\n",
      "1002\n",
      "1004\n",
      "1\n",
      "3\n",
      "1003\n",
      "8\n",
      "1007\n",
      "1009\n",
      "1008\n",
      "1012\n",
      "6\n",
      "1005\n",
      "1010\n",
      "5\n",
      "1001\n",
      "1\n",
      "1\n",
      "1001\n",
      "1003\n",
      "1\n",
      "1001\n",
      "2\n",
      "1002\n",
      "1001\n",
      "1\n",
      "1\n",
      "1001\n",
      "1006\n",
      "1003\n",
      "1004\n",
      "4\n",
      "5\n",
      "1007\n",
      "2\n",
      "1005\n",
      "3\n",
      "1008\n",
      "1002\n",
      "1001\n",
      "1\n",
      "1\n",
      "1001\n",
      "1002\n",
      "2\n",
      "1001\n",
      "1\n",
      "1002\n",
      "1001\n",
      "1\n",
      "2\n",
      "1002\n",
      "1003\n",
      "1001\n",
      "1\n",
      "2\n",
      "2\n",
      "1001\n",
      "1\n",
      "1002\n",
      "3\n",
      "1001\n",
      "2\n",
      "4\n",
      "3\n",
      "1\n",
      "1002\n",
      "1001\n",
      "1\n",
      "2\n",
      "3\n",
      "1001\n",
      "1\n",
      "1003\n",
      "1\n",
      "1002\n",
      "1001\n",
      "4\n",
      "3\n",
      "5\n",
      "1004\n",
      "2\n",
      "6\n",
      "5\n",
      "1003\n",
      "4\n",
      "1004\n",
      "1001\n",
      "1\n",
      "1002\n",
      "2\n",
      "1002\n",
      "1\n",
      "1001\n",
      "1\n",
      "1001\n",
      "1001\n",
      "1\n",
      "4\n",
      "3\n",
      "1002\n",
      "2\n",
      "5\n",
      "1007\n",
      "1006\n",
      "1004\n",
      "6\n",
      "1003\n",
      "1005\n",
      "1008\n",
      "1001\n",
      "1\n",
      "2\n",
      "1002\n",
      "1\n",
      "1001\n",
      "2\n",
      "1\n",
      "1001\n",
      "1001\n",
      "1\n",
      "2\n",
      "1001\n",
      "1\n",
      "1\n",
      "1001\n",
      "1001\n",
      "1\n",
      "1001\n",
      "1002\n",
      "1\n",
      "1001\n",
      "1\n",
      "1\n",
      "1003\n",
      "3\n",
      "1002\n",
      "1001\n",
      "2\n",
      "1001\n",
      "1\n",
      "1002\n",
      "1001\n",
      "1\n",
      "2\n",
      "1002\n",
      "1\n",
      "4\n",
      "5\n",
      "1006\n",
      "1003\n",
      "3\n",
      "1004\n",
      "1001\n",
      "1005\n",
      "1001\n",
      "1\n",
      "1001\n",
      "1\n",
      "1001\n",
      "2\n",
      "1\n",
      "3\n",
      "1001\n",
      "1\n",
      "1003\n",
      "2\n",
      "1002\n",
      "1001\n",
      "1\n",
      "3\n",
      "1001\n",
      "1\n",
      "1001\n",
      "1002\n",
      "1\n",
      "2\n",
      "1001\n",
      "1004\n",
      "1\n",
      "3\n",
      "1005\n",
      "1002\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "File b'bus_data/line_data/332.csv' does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-c0e8672937ae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[1;31m### Reading Data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"bus_data/line_data/\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mline\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\".csv\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlow_memory\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     df.columns = [\"Timestamp\", \"LineID\", \"JourneyPatternID\", \"TimeFrame\", \n\u001b[1;32m      6\u001b[0m                   \u001b[1;34m\"VehicleJourneyID\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Lon\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Lat\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"VehicleID\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"StopID\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\eogha\\Anaconda3\\envs\\comp47350\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, skip_footer, doublequote, delim_whitespace, as_recarray, compact_ints, use_unsigned, low_memory, buffer_lines, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    644\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    645\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 646\u001b[0;31m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    647\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    648\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\eogha\\Anaconda3\\envs\\comp47350\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    388\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 389\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    390\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mchunksize\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\eogha\\Anaconda3\\envs\\comp47350\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    728\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    729\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 730\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    731\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    732\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\eogha\\Anaconda3\\envs\\comp47350\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m    921\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'c'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    922\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'c'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 923\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    924\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    925\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'python'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\eogha\\Anaconda3\\envs\\comp47350\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1388\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'allow_leading_cols'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex_col\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1389\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1390\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_parser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1391\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1392\u001b[0m         \u001b[1;31m# XXX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas\\parser.pyx\u001b[0m in \u001b[0;36mpandas.parser.TextReader.__cinit__ (pandas\\parser.c:4184)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas\\parser.pyx\u001b[0m in \u001b[0;36mpandas.parser.TextReader._setup_parser_source (pandas\\parser.c:8449)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: File b'bus_data/line_data/332.csv' does not exist"
     ]
    }
   ],
   "source": [
    "for line in lines:\n",
    "    ### Reading Data\n",
    "\n",
    "    df = pd.read_csv(\"bus_data/line_data/\" + line + \".csv\", low_memory=False, header=None)\n",
    "    df.columns = [\"Timestamp\", \"LineID\", \"JourneyPatternID\", \"TimeFrame\", \n",
    "                  \"VehicleJourneyID\", \"Lon\", \"Lat\", \"VehicleID\", \"StopID\", \n",
    "                  \"AtStop\", \"HumanTime\", \"Day\", \"Hour\", \"Runtime\"]\n",
    "\n",
    "    #convert StopID to string\n",
    "\n",
    "    df['StopID'] = df['StopID'].astype('str')\n",
    "\n",
    "\n",
    "    ### Getting Stop Locations\n",
    "    # Isolating variations - getting variation with most stops\n",
    "\n",
    "    patterns = df['JourneyPatternID'].unique()\n",
    "\n",
    "    for pattern in patterns:\n",
    "        print(pattern)\n",
    "\n",
    "    # Concat location data\n",
    "\n",
    "    df['location'] = \"\"\n",
    "    df['location'] = df['Lon'].astype(str) + \"_\" + df['Lat'].astype(str)\n",
    "\n",
    "    stop_loc = {}\n",
    "\n",
    "    # Getting biggest pattern\n",
    "\n",
    "    max_pattern = df['JourneyPatternID'].value_counts().idxmax()\n",
    "    new_df = df[df.JourneyPatternID == max_pattern]\n",
    "\n",
    "    # cutting stops that don't appear more than 20 times\n",
    "\n",
    "    groups = new_df.groupby('StopID')\n",
    "    new_df = groups.filter(lambda x: len(x) > 20)\n",
    "\n",
    "    groups = new_df.groupby('StopID')\n",
    "\n",
    "    # Extracting the most frequent locations for each stop\n",
    "    loc_df = groups['location'].agg(lambda x:x.value_counts().index[0]).to_frame()\n",
    "    loc_df.reset_index(level=0, inplace=True)\n",
    "\n",
    "    # Converting location back to float columns\n",
    "    loc_df['Lon'], loc_df['Lat'] = loc_df['location'].str.split('_', 1).str\n",
    "    loc_df['Lon'], loc_df['Lat'] = loc_df['Lon'].astype('float64'), loc_df['Lat'].astype('float64')\n",
    "\n",
    "    # drop concatenated colum 'location'\n",
    "    loc_df = loc_df.drop('location', axis=1)\n",
    "\n",
    "    ### Getting Stop Orders\n",
    "\n",
    "    runtimes = new_df.groupby(\"StopID\").Runtime.mean()\n",
    "\n",
    "    order = runtimes.sort_values().to_frame()\n",
    "    order.reset_index(level=0, inplace=True)\n",
    "    order['Order'] = order.index\n",
    "\n",
    "    ### Merging dataframes and saving results\n",
    "\n",
    "    static_stops = pd.merge(order, loc_df, on='StopID')\n",
    "    static_stops\n",
    "\n",
    "    static_stops.to_csv('bus_data/static_data/routestops' + line + '.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
