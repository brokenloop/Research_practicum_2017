{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_schedule(schedule_file):\n",
    "    schedule = pd.read_csv(schedule_file, low_memory=False, encoding=\"ISO-8859-1\")\n",
    "    \n",
    "    return schedule\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_schedule(schedule):\n",
    "    \n",
    "    # drop null values\n",
    "    schedule.dropna(0, inplace=True)\n",
    "    \n",
    "    # extract StopID\n",
    "    schedule[\"StopID\"] = schedule['stop_id'].apply(lambda x: x[-4:])\n",
    "    \n",
    "    # Convert StopIDs back to int\n",
    "    schedule['StopID'] = schedule['StopID'].astype('int64')\n",
    "    \n",
    "    # Extracting LineID from trip_id\n",
    "    schedule[\"LineID\"] = schedule[\"trip_id\"].str.extract('\\-(.*?)\\-')\n",
    "    \n",
    "    # Extracting direction from trip_id\n",
    "    schedule[\"Direction\"] = schedule['trip_id'].apply(lambda x: x[-1:])\n",
    "    \n",
    "    # Dropping non-major journeypatterns\n",
    "    schedule = schedule[(schedule.Direction == \"I\") | (schedule.Direction == \"O\")]\n",
    "    \n",
    "    # Converting Direction to JourneyPatternID\n",
    "    schedule[\"JourneyPatternID\"] = schedule['Direction'].apply(lambda x: \"1001\" if x == \"I\" else \"0001\")\n",
    "    schedule['JourneyPatternID'] = schedule['JourneyPatternID'].astype('int64')\n",
    "    \n",
    "#     # dropping irrelevant columns\n",
    "#     for column in ['trip_id', 'stop_id', 'arrival_time', 'departure_time', \n",
    "#                    'shape_dist_traveled', 'Direction', 'stop_sequence', 'stop_headsign']:\n",
    "#             schedule = schedule.drop(column, 1)\n",
    "            \n",
    "    # Renaming 'Long' to 'Lon'\n",
    "    schedule = schedule.rename(columns={'Long': 'Lon'})\n",
    "    \n",
    "    return schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# MIGHT HAVE TO CHANGE COLUMN NAMES - NOT SURE IF I HAVE THE CORRECT AMOUNT\n",
    "\n",
    "def read_data(filename):\n",
    "\n",
    "    df = pd.read_csv(filename, low_memory=False, header=None)\n",
    "    df.columns = [\"Timestamp\", \"LineID\", \"Direction\", \"JourneyPatternID\", \"TimeFrame\",\n",
    "                  \"VehicleJourneyID\", \"Operator\", \"Congestion\", \"Lon\", \"Lat\",\n",
    "                  \"Delay\", \"BlockID\", \"VehicleID\", \"StopID\", \"AtStop\"]\n",
    "    \n",
    "    \n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ADDING HOUR, DAY, HUMANTIME COLUMNS\n",
    "# DROPPING IRRELEVANT COLUMNS\n",
    "# CAN REMAIN UNCHANGED - MIGHT WANT TO MAKE HOUR MORE GRANULAR? \n",
    "\n",
    "def add_features(df):\n",
    "\n",
    "    # Add column for human readable time\n",
    "    df['HumanTime'] = pd.to_datetime(df['Timestamp'], unit='us')\n",
    "\n",
    "\n",
    "    # Add day of week column\n",
    "    df['Day'] = df['HumanTime'].dt.dayofweek\n",
    "\n",
    "    # Add hour of day column\n",
    "    df['Hour'] = df['HumanTime'].dt.hour\n",
    "\n",
    "\n",
    "    # Dropping irrelevant columns\n",
    "    for column in ['BlockID', 'Direction', 'Operator', 'Delay', 'Congestion']:\n",
    "        df = df.drop(column, 1)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_journeygroup(df):\n",
    "    # For testing only - filter_direction is causing errors\n",
    "    # So we need to test\n",
    "    # converting data, adding compound feature\n",
    "    for column in ['TimeFrame', 'VehicleJourneyID',]:\n",
    "            df[column] = df[column].astype('str')\n",
    "\n",
    "    df[\"JourneyGroup\"] = df[\"TimeFrame\"] + df[\"VehicleJourneyID\"]\n",
    "    \n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# REMOVING STOPS THAT AREN'T IN THE SCHEDULE. \n",
    "\n",
    "def schedule_validate(df, schedule):\n",
    "    schedule_stops = schedule.StopID.unique().tolist()\n",
    "    \n",
    "    df = df[df.StopID.isin(schedule_stops)]\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def filter_direction2(df, schedule):\n",
    "    \n",
    "    # casting StopID to int, removing null values:\n",
    "    try:\n",
    "        df['StopID'] = df['StopID'].astype('int64')\n",
    "    except:\n",
    "        df = df[df.StopID != 'null']\n",
    "        df['StopID'] = df['StopID'].astype('int64')\n",
    "    \n",
    "    # getting line variable\n",
    "    line = df.LineID.iloc[0]\n",
    "    line = str(line)\n",
    "\n",
    "    # converting data, adding compound feature\n",
    "    for column in ['TimeFrame', 'VehicleJourneyID',]:\n",
    "            df[column] = df[column].astype('str')\n",
    "\n",
    "    # creating compound feature, getting patterns, creating temp df\n",
    "    df[\"JourneyGroup\"] = df[\"TimeFrame\"] + df[\"VehicleJourneyID\"]\n",
    "    patterns = df.JourneyPatternID.unique()\n",
    "    tempdf = pd.DataFrame()\n",
    "\n",
    "    for pattern in patterns:\n",
    "        \n",
    "        # Getting first 5 stops for all variations in schedule \n",
    "        pattern_sched = schedule[(schedule.LineID == line) & (schedule.JourneyPatternID == pattern)]\n",
    "        starting_stops = set()\n",
    "        headsigns = pattern_sched.stop_headsign.unique()\n",
    "        for sign in headsigns:\n",
    "            headsign_sched = pattern_sched[pattern_sched.stop_headsign == sign]\n",
    "            first_5 = set(headsign_sched.head(5).StopID.tolist())\n",
    "            starting_stops = first_5.union(starting_stops)\n",
    "            \n",
    "        starting_stops = list(starting_stops)\n",
    "                \n",
    "        # Getting first stops of all journeys in our data\n",
    "        patterndf = df[df.JourneyPatternID == pattern]\n",
    "        firstlines = patterndf.groupby([\"TimeFrame\", \"VehicleJourneyID\"]).head(1)\n",
    "        \n",
    "        # removing stops from our data that don't appear in schedule \n",
    "        patterndf = schedule_validate(patterndf, pattern_sched)\n",
    "\n",
    "        # Getting all journeys that start at in the first 5\n",
    "        valid_journeys = []\n",
    "        for index, row in firstlines.iterrows():\n",
    "            if row.StopID in starting_stops:\n",
    "                valid_journeys.append(row.JourneyGroup)\n",
    "\n",
    "        # removing journeys that don't start at the right stop\n",
    "        patterndf = patterndf[patterndf.JourneyGroup.isin(valid_journeys)]\n",
    "\n",
    "        if tempdf.empty:\n",
    "            tempdf = patterndf\n",
    "        else: \n",
    "            tempdf = pd.concat([tempdf, patterndf], axis=0)\n",
    "\n",
    "    return tempdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# DROPPING ROWS WHERE BUS ISN'T AT STOP \n",
    "# THIS SECTION NEEDS TO BE CHANGED, INCLUDE ONLY ROWS WHERE STOPID CHANGES\n",
    "\n",
    "def drop_rows(df):\n",
    "\n",
    "    # drop duplicate rows\n",
    "    df = df.drop_duplicates([\"TimeFrame\", \"VehicleJourneyID\", \"StopID\"])\n",
    "\n",
    "    # mean = df.JourneyGroup.value_counts().mean()\n",
    "    # drop trips with less than 5 stops\n",
    "    df = df[df.groupby('JourneyGroup').JourneyGroup.transform(len) > 5]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def runtime_function(row, mydict):\n",
    "    # Takes a row and a dictionary of start times\n",
    "    # returns time elapsed (seconds) between that row's timestamp and the start of the line\n",
    "#     start = mydict[row.TimeFrame, row.VehicleID, row.VehicleJourneyID][\"time\"]\n",
    "    start = mydict[row.TimeFrame, row.VehicleJourneyID][\"time\"]\n",
    "    \n",
    "    current = row.Timestamp\n",
    "    \n",
    "    if current - start < 0:\n",
    "        print(row.StopID, \"negative value\")\n",
    "    return (current - start) // 1000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ADDING RUNTIME COLUMN - THIS CAN REMAIN UNCHANGED\n",
    "\n",
    "def add_runtime(df):\n",
    "    # Putting the first sightings of a vehiclejourneyid and timeframe combo timestamp into a dictionary\n",
    "    start_times = {}\n",
    "    \n",
    "#     df = df.sort_values(['Timestamp'])\n",
    "\n",
    "    df = df.sort_values(['Timestamp'])\n",
    "\n",
    "    # This gives you the first line anything has been seen by\n",
    "#     firstlines = df.groupby([\"TimeFrame\", \"VehicleID\", \"VehicleJourneyID\"]).head(1)\n",
    "    firstlines = df.groupby([\"TimeFrame\", \"VehicleJourneyID\"]).head(1)\n",
    "\n",
    "\n",
    "    # This iterates through them and assigns values to the dictionary\n",
    "    for index, row in firstlines.iterrows():\n",
    "        start_times[row.TimeFrame, row.VehicleJourneyID] = {\"time\":row.Timestamp, \"loc\":[row.Lat, row.Lon]}\n",
    "\n",
    "#         start_times[row.TimeFrame, row.VehicleID, row.VehicleJourneyID] = {\"time\":row.Timestamp, \"loc\":[row.Lat, row.Lon]}\n",
    "\n",
    "\n",
    "    df['Runtime'] = \"\"\n",
    "\n",
    "    # Applies this function to the newdf\n",
    "    df['Runtime'] = df.apply(lambda row: runtime_function(row, start_times),axis=1)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def insert_into_file(df, writefile):\n",
    "    \"\"\"  This function writes a dataframe (df) to a file (writefile),\n",
    "        or does nothing if the file doesn't exist\n",
    "        \n",
    "        CHANGED FROM OTHER\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(writefile, 'a') as f:\n",
    "#             df.to_csv(f, header=False, index=False)\n",
    "            print(writefile, \"exists\")\n",
    "            pass\n",
    "    except IOError:\n",
    "        with open(writefile, 'w+') as f:\n",
    "            df.to_csv(f, header=False, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def main(read_directory, schedule_file, write_directory):\n",
    "    \n",
    "    schedule = read_schedule(schedule_file)\n",
    "    schedule = clean_schedule(schedule)\n",
    "    \n",
    "    for read_file in os.listdir(read_directory):\n",
    "        if read_file.endswith(\".csv\"):\n",
    "            if os.path.isfile(write_directory + \"/\" + read_file):\n",
    "                print(read_file, \"exists\")\n",
    "            else:\n",
    "                print(\"Reading\", read_file, \"from\", read_directory)\n",
    "                try:\n",
    "                    df = read_data(read_directory + \"/\" + read_file)\n",
    "                    df = add_features(df)\n",
    "                    df = filter_direction2(df, schedule)\n",
    "                    df = add_journeygroup(df)\n",
    "                    df = drop_rows(df)\n",
    "                    df = add_runtime(df)\n",
    "        \n",
    "\n",
    "\n",
    "                    with open(write_directory + \"/\" + read_file, 'w+') as f:\n",
    "                        df.to_csv(f, header=False, index=False)\n",
    "                except (ValueError, IndexError) as error:\n",
    "                    print(error, \"!\")\n",
    "                    print(\"Couldn't finish\", read_file)\n",
    "                    \n",
    "\n",
    "                print(\"Finished\", read_file)\n",
    "                print()\n",
    "    print(\"Finished main!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/danieljordan/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:13: FutureWarning: currently extract(expand=None) means expand=False (return Index/Series/DataFrame) but in a future version of pandas this will be changed to expand=True (return DataFrame)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading 1.csv from bus_data/line_data2\n",
      "Finished 1.csv\n",
      "\n",
      "Reading 102.csv from bus_data/line_data2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/danieljordan/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/danieljordan/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/danieljordan/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished 102.csv\n",
      "\n",
      "Reading 104.csv from bus_data/line_data2\n",
      "Finished 104.csv\n",
      "\n",
      "Reading 11.csv from bus_data/line_data2\n",
      "Finished 11.csv\n",
      "\n",
      "Reading 111.csv from bus_data/line_data2\n",
      "Finished 111.csv\n",
      "\n",
      "Reading 114.csv from bus_data/line_data2\n",
      "Finished 114.csv\n",
      "\n",
      "Reading 116.csv from bus_data/line_data2\n",
      "Finished 116.csv\n",
      "\n",
      "Reading 118.csv from bus_data/line_data2\n",
      "Finished 118.csv\n",
      "\n",
      "Reading 120.csv from bus_data/line_data2\n",
      "Finished 120.csv\n",
      "\n",
      "Reading 122.csv from bus_data/line_data2\n",
      "Finished 122.csv\n",
      "\n",
      "Reading 123.csv from bus_data/line_data2\n",
      "Finished 123.csv\n",
      "\n",
      "Reading 13.csv from bus_data/line_data2\n",
      "Finished 13.csv\n",
      "\n",
      "Reading 130.csv from bus_data/line_data2\n",
      "Finished 130.csv\n",
      "\n",
      "Reading 14.csv from bus_data/line_data2\n",
      "Finished 14.csv\n",
      "\n",
      "Reading 140.csv from bus_data/line_data2\n",
      "Finished 140.csv\n",
      "\n",
      "Reading 142.csv from bus_data/line_data2\n",
      "Finished 142.csv\n",
      "\n",
      "Reading 145.csv from bus_data/line_data2\n",
      "Finished 145.csv\n",
      "\n",
      "Reading 14C.csv from bus_data/line_data2\n",
      "Finished 14C.csv\n",
      "\n",
      "Reading 15.csv from bus_data/line_data2\n",
      "Finished 15.csv\n",
      "\n",
      "Reading 150.csv from bus_data/line_data2\n",
      "Finished 150.csv\n",
      "\n",
      "Reading 151.csv from bus_data/line_data2\n",
      "Finished 151.csv\n",
      "\n",
      "Reading 15A.csv from bus_data/line_data2\n",
      "Finished 15A.csv\n",
      "\n",
      "Reading 15B.csv from bus_data/line_data2\n",
      "Finished 15B.csv\n",
      "\n",
      "Reading 16.csv from bus_data/line_data2\n",
      "Finished 16.csv\n",
      "\n",
      "Reading 161.csv from bus_data/line_data2\n",
      "Finished 161.csv\n",
      "\n",
      "Reading 16C.csv from bus_data/line_data2\n",
      "Finished 16C.csv\n",
      "\n",
      "Reading 17.csv from bus_data/line_data2\n",
      "Finished 17.csv\n",
      "\n",
      "Reading 17A.csv from bus_data/line_data2\n",
      "Finished 17A.csv\n",
      "\n",
      "Reading 18.csv from bus_data/line_data2\n",
      "Finished 18.csv\n",
      "\n",
      "Reading 184.csv from bus_data/line_data2\n",
      "Finished 184.csv\n",
      "\n",
      "Reading 185.csv from bus_data/line_data2\n",
      "Finished 185.csv\n",
      "\n",
      "Reading 220.csv from bus_data/line_data2\n",
      "Finished 220.csv\n",
      "\n",
      "Reading 236.csv from bus_data/line_data2\n",
      "Finished 236.csv\n",
      "\n",
      "Reading 238.csv from bus_data/line_data2\n",
      "Finished 238.csv\n",
      "\n",
      "Reading 239.csv from bus_data/line_data2\n",
      "Finished 239.csv\n",
      "\n",
      "Reading 25.csv from bus_data/line_data2\n",
      "Finished 25.csv\n",
      "\n",
      "Reading 25A.csv from bus_data/line_data2\n",
      "Finished 25A.csv\n",
      "\n",
      "Reading 25B.csv from bus_data/line_data2\n",
      "Finished 25B.csv\n",
      "\n",
      "Reading 25X.csv from bus_data/line_data2\n",
      "Finished 25X.csv\n",
      "\n",
      "Reading 26.csv from bus_data/line_data2\n",
      "Finished 26.csv\n",
      "\n",
      "Reading 27.csv from bus_data/line_data2\n",
      "Finished 27.csv\n",
      "\n",
      "Reading 270.csv from bus_data/line_data2\n",
      "Finished 270.csv\n",
      "\n",
      "Reading 27A.csv from bus_data/line_data2\n",
      "Finished 27A.csv\n",
      "\n",
      "Reading 27B.csv from bus_data/line_data2\n",
      "Finished 27B.csv\n",
      "\n",
      "Reading 27X.csv from bus_data/line_data2\n",
      "Finished 27X.csv\n",
      "\n",
      "Reading 29A.csv from bus_data/line_data2\n",
      "Finished 29A.csv\n",
      "\n",
      "Reading 31.csv from bus_data/line_data2\n",
      "Finished 31.csv\n",
      "\n",
      "Reading 31A.csv from bus_data/line_data2\n",
      "Finished 31A.csv\n",
      "\n",
      "Reading 31B.csv from bus_data/line_data2\n",
      "Finished 31B.csv\n",
      "\n",
      "Reading 32.csv from bus_data/line_data2\n",
      "Finished 32.csv\n",
      "\n",
      "Reading 32A.csv from bus_data/line_data2\n",
      "Cannot set a frame with no defined index and a value that cannot be converted to a Series !\n",
      "Couldn't finish 32A.csv\n",
      "Finished 32A.csv\n",
      "\n",
      "Reading 32B.csv from bus_data/line_data2\n",
      "Cannot set a frame with no defined index and a value that cannot be converted to a Series !\n",
      "Couldn't finish 32B.csv\n",
      "Finished 32B.csv\n",
      "\n",
      "Reading 32X.csv from bus_data/line_data2\n",
      "Finished 32X.csv\n",
      "\n",
      "Reading 33.csv from bus_data/line_data2\n",
      "Finished 33.csv\n",
      "\n",
      "Reading 33A.csv from bus_data/line_data2\n",
      "Finished 33A.csv\n",
      "\n",
      "Reading 33B.csv from bus_data/line_data2\n",
      "Finished 33B.csv\n",
      "\n",
      "Reading 33X.csv from bus_data/line_data2\n",
      "Finished 33X.csv\n",
      "\n",
      "Reading 37.csv from bus_data/line_data2\n",
      "Finished 37.csv\n",
      "\n",
      "Reading 38.csv from bus_data/line_data2\n",
      "Finished 38.csv\n",
      "\n",
      "Reading 38A.csv from bus_data/line_data2\n",
      "Finished 38A.csv\n",
      "\n",
      "Reading 38B.csv from bus_data/line_data2\n",
      "Finished 38B.csv\n",
      "\n",
      "Reading 39.csv from bus_data/line_data2\n",
      "Finished 39.csv\n",
      "\n",
      "Reading 39A.csv from bus_data/line_data2\n",
      "Finished 39A.csv\n",
      "\n",
      "Reading 4.csv from bus_data/line_data2\n",
      "Finished 4.csv\n",
      "\n",
      "Reading 40.csv from bus_data/line_data2\n",
      "Finished 40.csv\n",
      "\n",
      "Reading 40B.csv from bus_data/line_data2\n",
      "Finished 40B.csv\n",
      "\n",
      "Reading 40D.csv from bus_data/line_data2\n",
      "Finished 40D.csv\n",
      "\n",
      "Reading 41.csv from bus_data/line_data2\n",
      "Finished 41.csv\n",
      "\n",
      "Reading 41A.csv from bus_data/line_data2\n",
      "Finished 41A.csv\n",
      "\n",
      "Reading 41B.csv from bus_data/line_data2\n",
      "Finished 41B.csv\n",
      "\n",
      "Reading 41C.csv from bus_data/line_data2\n",
      "Finished 41C.csv\n",
      "\n",
      "Reading 41X.csv from bus_data/line_data2\n",
      "Finished 41X.csv\n",
      "\n",
      "Reading 42.csv from bus_data/line_data2\n",
      "Finished 42.csv\n",
      "\n",
      "Reading 43.csv from bus_data/line_data2\n",
      "Finished 43.csv\n",
      "\n",
      "Reading 44.csv from bus_data/line_data2\n",
      "Finished 44.csv\n",
      "\n",
      "Reading 44B.csv from bus_data/line_data2\n",
      "Finished 44B.csv\n",
      "\n",
      "Reading 45A.csv from bus_data/line_data2\n",
      "Finished 45A.csv\n",
      "\n",
      "Reading 46A.csv from bus_data/line_data2\n",
      "Finished 46A.csv\n",
      "\n",
      "Reading 46E.csv from bus_data/line_data2\n",
      "Finished 46E.csv\n",
      "\n",
      "Reading 47.csv from bus_data/line_data2\n",
      "Finished 47.csv\n",
      "\n",
      "Reading 49.csv from bus_data/line_data2\n",
      "Finished 49.csv\n",
      "\n",
      "Reading 51D.csv from bus_data/line_data2\n",
      "Finished 51D.csv\n",
      "\n",
      "Reading 51X.csv from bus_data/line_data2\n",
      "Finished 51X.csv\n",
      "\n",
      "Reading 53.csv from bus_data/line_data2\n",
      "Finished 53.csv\n",
      "\n",
      "Reading 53B.csv from bus_data/line_data2\n",
      "Cannot set a frame with no defined index and a value that cannot be converted to a Series !\n",
      "Couldn't finish 53B.csv\n",
      "Finished 53B.csv\n",
      "\n",
      "Reading 54A.csv from bus_data/line_data2\n",
      "Finished 54A.csv\n",
      "\n",
      "Reading 56A.csv from bus_data/line_data2\n",
      "Finished 56A.csv\n",
      "\n",
      "Reading 59.csv from bus_data/line_data2\n",
      "Finished 59.csv\n",
      "\n",
      "Reading 61.csv from bus_data/line_data2\n",
      "Finished 61.csv\n",
      "\n",
      "Reading 63.csv from bus_data/line_data2\n",
      "Finished 63.csv\n",
      "\n",
      "Reading 65.csv from bus_data/line_data2\n",
      "Finished 65.csv\n",
      "\n",
      "Reading 65B.csv from bus_data/line_data2\n",
      "Finished 65B.csv\n",
      "\n",
      "Reading 66.csv from bus_data/line_data2\n",
      "Finished 66.csv\n",
      "\n",
      "Reading 66A.csv from bus_data/line_data2\n",
      "Finished 66A.csv\n",
      "\n",
      "Reading 66B.csv from bus_data/line_data2\n",
      "Finished 66B.csv\n",
      "\n",
      "Reading 66X.csv from bus_data/line_data2\n",
      "Finished 66X.csv\n",
      "\n",
      "Reading 67.csv from bus_data/line_data2\n",
      "Finished 67.csv\n",
      "\n",
      "Reading 67X.csv from bus_data/line_data2\n",
      "Finished 67X.csv\n",
      "\n",
      "Reading 68.csv from bus_data/line_data2\n",
      "Finished 68.csv\n",
      "\n",
      "Reading 68A.csv from bus_data/line_data2\n",
      "Finished 68A.csv\n",
      "\n",
      "Reading 69.csv from bus_data/line_data2\n",
      "Finished 69.csv\n",
      "\n",
      "Reading 69X.csv from bus_data/line_data2\n",
      "Finished 69X.csv\n",
      "\n",
      "Reading 7.csv from bus_data/line_data2\n",
      "Finished 7.csv\n",
      "\n",
      "Reading 70.csv from bus_data/line_data2\n",
      "Finished 70.csv\n",
      "\n",
      "Reading 747.csv from bus_data/line_data2\n",
      "Finished 747.csv\n",
      "\n",
      "Reading 75.csv from bus_data/line_data2\n",
      "Finished 75.csv\n",
      "\n",
      "Reading 76.csv from bus_data/line_data2\n",
      "Finished 76.csv\n",
      "\n",
      "Reading 76A.csv from bus_data/line_data2\n",
      "Finished 76A.csv\n",
      "\n",
      "Reading 77A.csv from bus_data/line_data2\n",
      "Finished 77A.csv\n",
      "\n",
      "Reading 79.csv from bus_data/line_data2\n",
      "Finished 79.csv\n",
      "\n",
      "Reading 79A.csv from bus_data/line_data2\n",
      "Finished 79A.csv\n",
      "\n",
      "Reading 7B.csv from bus_data/line_data2\n",
      "Finished 7B.csv\n",
      "\n",
      "Reading 7D.csv from bus_data/line_data2\n",
      "Finished 7D.csv\n",
      "\n",
      "Reading 8.csv from bus_data/line_data2\n",
      "Finished 8.csv\n",
      "\n",
      "Reading 83.csv from bus_data/line_data2\n",
      "Finished 83.csv\n",
      "\n",
      "Reading 83A.csv from bus_data/line_data2\n",
      "Finished 83A.csv\n",
      "\n",
      "Reading 84.csv from bus_data/line_data2\n",
      "Finished 84.csv\n",
      "\n",
      "Reading 84A.csv from bus_data/line_data2\n",
      "Finished 84A.csv\n",
      "\n",
      "Reading 84X.csv from bus_data/line_data2\n",
      "Finished 84X.csv\n",
      "\n",
      "Reading 9.csv from bus_data/line_data2\n",
      "Finished 9.csv\n",
      "\n",
      "Reading PP07.csv from bus_data/line_data2\n",
      "Cannot set a frame with no defined index and a value that cannot be converted to a Series !\n",
      "Couldn't finish PP07.csv\n",
      "Finished PP07.csv\n",
      "\n",
      "Finished main!\n"
     ]
    }
   ],
   "source": [
    "# MAIN SECTION\n",
    "\n",
    "read_directory = \"bus_data/line_data2\"\n",
    "write_directory = \"bus_data/clean_data5\"\n",
    "\n",
    "\n",
    "schedule_file = 'bus_data/dublinbus_scheduledData2013csv.csv'\n",
    "\n",
    "main(read_directory, schedule_file, write_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/danieljordan/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:13: FutureWarning: currently extract(expand=None) means expand=False (return Index/Series/DataFrame) but in a future version of pandas this will be changed to expand=True (return DataFrame)\n",
      "/Users/danieljordan/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/danieljordan/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/danieljordan/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "line = \"102\"\n",
    "\n",
    "readfile = \"bus_data/line_data2/\" + line + \".csv\"\n",
    "\n",
    "\n",
    "schedule_file = 'bus_data/dublinbus_scheduledData2013csv.csv'\n",
    "schedule = read_schedule(schedule_file)\n",
    "schedule = clean_schedule(schedule)\n",
    "    \n",
    "    \n",
    "df = read_data(readfile)\n",
    "df = add_features(df)\n",
    "df = filter_direction2(df, schedule)\n",
    "df = add_journeygroup(df)\n",
    "df = drop_rows(df)\n",
    "\n",
    "# df.to_csv('bus_data/clean_data_rough/' + line + '.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "newdf = add_runtime(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# newdf.to_csv('bus_data/clean_data_rough/' + line + '.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], Name: StopID, dtype: int64)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newdf[newdf.Runtime < 0].StopID.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = df[df.JourneyPatternID == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.StopID.unique().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "out = df[df.JourneyPatternID == 1]\n",
    "\n",
    "out = out.groupby(['StopID'])['Runtime'].mean().reset_index()\n",
    "\n",
    "# out\n",
    "# out.sort_values(['Runtime'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "journeys = df.JourneyGroup.unique()\n",
    "journeys = journeys[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "negs = df[(df.Runtime < 0)]\n",
    "negs.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# for index in journeys:\n",
    "#     for i in range(1000):\n",
    "#         first = df[df.JourneyGroup == index].head(1)\n",
    "#     #     if first.Runtime < 0:\n",
    "#     #         print(first[['HumanTime', 'Runtime']])\n",
    "#         print(first[['JourneyGroup', 'Runtime']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "journey = df[df.JourneyGroup == \"2012-11-065815\"]\n",
    "times = journey[['HumanTime', 'Runtime']]\n",
    "\n",
    "# middle = journey[(journey.Runtime < 10000) & (times.Runtime > -1000)]\n",
    "\n",
    "# middle\n",
    "\n",
    "journey.tail()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 6282"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "times.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.JourneyGroup.value_counts().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "locations = newdf[[\"Lon\", \"Lat\"]]\n",
    "locations.plot.scatter(x=\"Lon\", y=\"Lat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "newdf.JourneyGroup.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xxxx = df[df.JourneyGroup == \"2013-01-085057\"]\n",
    "xxxx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "firstlines = patterndf.groupby([\"TimeFrame\", \"VehicleJourneyID\"]).head(1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ADDING RUNTIME COLUMN - THIS CAN REMAIN UNCHANGED\n",
    "\n",
    "# # Putting the first sightings of a vehiclejourneyid and timeframe combo timestamp into a dictionary\n",
    "# start_times = {}\n",
    "\n",
    "# # This gives you the first line anything has been seen by\n",
    "# firstlines = df.groupby([\"TimeFrame\", \"VehicleJourneyID\"]).head(1)\n",
    "\n",
    "# # This iterates through them and assigns values to the dictionary\n",
    "# for index, row in firstlines.iterrows():\n",
    "#     start_times[row.TimeFrame, row.VehicleJourneyID] = {\"time\":row.Timestamp, \"loc\":[row.Lat, row.Lon]}\n",
    "\n",
    "\n",
    "# df['Runtime'] = \"\"\n",
    "\n",
    "# # Applies this function to the newdf\n",
    "# df['Runtime'] = df.apply(lambda row: add_runtime(row, start_times),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
